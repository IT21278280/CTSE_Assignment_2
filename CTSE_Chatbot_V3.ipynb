{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ae8ad4",
   "metadata": {},
   "source": [
    "# CTSE Lecture Notes Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7761c7e",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582f54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the CTSE Lecture Notes Chatbot\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import PyPDF2\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d474b",
   "metadata": {},
   "source": [
    "Set Up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2837543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for debugging and monitoring\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Specify Tesseract path (Windows example; adjust for your system)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Uncomment and adjust if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57d629",
   "metadata": {},
   "source": [
    "Define Text Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dd3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text function to remove artifacts and improve formatting\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text.strip())\n",
    "    text = re.sub(r'●|\\○|\\-|\\+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065659d5",
   "metadata": {},
   "source": [
    "Load and Process Lecture Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a443d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process lecture notes with page tracking and OCR fallback\n",
    "def load_and_process_documents():\n",
    "    logging.info(\"Loading and processing lecture notes...\")\n",
    "    notes_dir = './lecture_notes/'\n",
    "    if not os.path.exists(notes_dir):\n",
    "        logging.error(f\"Directory {notes_dir} not found.\")\n",
    "        print(f\"Directory {notes_dir} not found. Please create it and add PDF files.\")\n",
    "        return None\n",
    "\n",
    "    documents = []\n",
    "    for pdf_file in os.listdir(notes_dir):\n",
    "        if pdf_file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(notes_dir, pdf_file)\n",
    "            try:\n",
    "                with open(pdf_path, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    text_extracted = False\n",
    "                    for page_num in range(len(pdf_reader.pages)):\n",
    "                        page = pdf_reader.pages[page_num]\n",
    "                        text = page.extract_text()\n",
    "                        if text and text.strip():\n",
    "                            cleaned_text = clean_text(text)\n",
    "                            doc = Document(page_content=cleaned_text, metadata={\"source\": pdf_file, \"page\": page_num + 1})\n",
    "                            documents.append(doc)\n",
    "                            text_extracted = True\n",
    "                        else:\n",
    "                            logging.warning(f\"No text extracted from {pdf_file}, page {page_num + 1}. Falling back to OCR.\")\n",
    "                            break\n",
    "\n",
    "                if not text_extracted:\n",
    "                    logging.info(f\"Using OCR for {pdf_file}...\")\n",
    "                    images = convert_from_path(pdf_path)\n",
    "                    for page_num, image in enumerate(images):\n",
    "                        text = pytesseract.image_to_string(image)\n",
    "                        if text and text.strip():\n",
    "                            cleaned_text = clean_text(text)\n",
    "                            doc = Document(page_content=cleaned_text, metadata={\"source\": pdf_file, \"page\": page_num + 1})\n",
    "                            documents.append(doc)\n",
    "                        else:\n",
    "                            logging.warning(f\"OCR failed to extract text from {pdf_file}, page {page_num + 1}.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {pdf_file}: {e}\")\n",
    "                print(f\"Error processing {pdf_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not documents:\n",
    "        logging.error(\"No documents loaded after processing.\")\n",
    "        print(\"No documents loaded. Ensure PDFs are text-based or OCR-compatible.\")\n",
    "        return None\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"])\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    logging.info(f\"Created {len(chunks)} chunks.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d46b5",
   "metadata": {},
   "source": [
    "Set Up Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ddf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up vector store with FAISS\n",
    "def setup_vector_store(chunks):\n",
    "    logging.info(\"Setting up vector store...\")\n",
    "    faiss_index_path = './faiss_index'\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    if os.path.exists(faiss_index_path):\n",
    "        vector_store = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6ce16",
   "metadata": {},
   "source": [
    "Set Up Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fd0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama LLM with Gemma:2b\n",
    "def setup_llm():\n",
    "    logging.info(\"Initializing Ollama LLM with Gemma:2b...\")\n",
    "    try:\n",
    "        return OllamaLLM(model=\"gemma:2b\", temperature=0.3)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error initializing Ollama: {e}\")\n",
    "        print(f\"Error initializing Ollama: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c23ce2",
   "metadata": {},
   "source": [
    "Build RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f5a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 20:08:22,037 - INFO - Loading and processing lecture notes...\n",
      "2025-05-12 20:08:33,516 - WARNING - No text extracted from lecture4.pdf, page 13. Falling back to OCR.\n",
      "2025-05-12 20:08:33,527 - INFO - Created 163 chunks.\n",
      "2025-05-12 20:08:33,533 - INFO - Setting up vector store...\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9328\\1766099148.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "2025-05-12 20:09:14,367 - INFO - Use pytorch device_name: cpu\n",
      "2025-05-12 20:09:14,370 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-05-12 20:09:19,851 - INFO - Loading faiss with AVX512 support.\n",
      "2025-05-12 20:09:19,853 - INFO - Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "2025-05-12 20:09:19,856 - INFO - Loading faiss with AVX2 support.\n",
      "2025-05-12 20:09:20,051 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2025-05-12 20:09:20,084 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-05-12 20:09:20,101 - INFO - Initializing Ollama LLM with Gemma:2b...\n",
      "2025-05-12 20:09:23,176 - INFO - Building RAG pipeline...\n"
     ]
    }
   ],
   "source": [
    "# Build Retrieval-Augmented Generation (RAG) pipeline\n",
    "def setup_qa_chain(vector_store, llm):\n",
    "    logging.info(\"Building RAG pipeline...\")\n",
    "    prompt_template = \"\"\"\n",
    "    You are a specialized assistant for Current Trends in Software Engineering (CTSE) lecture notes. Your task is to provide a clear, concise, and accurate answer using *only* the exact text from the provided CTSE lecture notes. Copy the relevant sentence(s) or phrase(s) directly from the context without adding, modifying, or elaborating on the content. Use bullet points or short sentences for clarity. If the question is unrelated to CTSE lecture notes (e.g., sports, general knowledge), respond exactly with: 'This question is outside the scope of CTSE lecture notes. Please ask about topics from the lecture notes.' If no relevant information is found, respond exactly with: 'No relevant information found in the CTSE lecture notes.'\n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "# Load data and set up the chatbot\n",
    "chunks = load_and_process_documents()\n",
    "if chunks:\n",
    "    vector_store = setup_vector_store(chunks)\n",
    "    llm = setup_llm()\n",
    "    if vector_store and llm:\n",
    "        qa_chain = setup_qa_chain(vector_store, llm)\n",
    "    else:\n",
    "        print(\"Failed to set up chatbot. Check logs.\")\n",
    "        raise SystemExit\n",
    "else:\n",
    "    raise SystemExit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf05c",
   "metadata": {},
   "source": [
    "Implement Chatbot Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de220713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ask questions with improved retrieval and concise output\n",
    "def ask_question(question):\n",
    "    if qa_chain:\n",
    "        try:\n",
    "            # Extract lecture name and page range from the question (if applicable)\n",
    "            lecture_match = re.search(r'Lecture(\\d+)', question, re.IGNORECASE)\n",
    "            page_range = None\n",
    "            if \"first 2 page\" in question.lower() or \"page 1 to 2\" in question.lower():\n",
    "                page_range = [1, 2]\n",
    "\n",
    "            if lecture_match and page_range:\n",
    "                lecture_num = lecture_match.group(1)\n",
    "                lecture_file = f\"lecture{lecture_num}.pdf\"\n",
    "                filtered_docs = [doc for doc in chunks if doc.metadata[\"source\"] == lecture_file and doc.metadata[\"page\"] in page_range]\n",
    "                if not filtered_docs:\n",
    "                    return \"No content found for the first two pages of Lecture {}.\".format(lecture_num), \"\"\n",
    "                temp_vector_store = FAISS.from_documents(filtered_docs, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "                temp_qa_chain = RetrievalQA.from_chain_type(\n",
    "                    llm=llm,\n",
    "                    chain_type=\"stuff\",\n",
    "                    retriever=temp_vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                    return_source_documents=True,\n",
    "                    chain_type_kwargs={\"prompt\": qa_chain.combine_documents_chain.llm_chain.prompt}\n",
    "                )\n",
    "                result = temp_qa_chain.invoke({\"query\": question})\n",
    "            else:\n",
    "                # For general questions, use the main vector store with a refined keyword filter\n",
    "                keywords = [word for word in question.lower().split() if word not in ['what', 'is', 'in', 'the', 'a', 'an']]\n",
    "                filtered_docs = [\n",
    "                    doc for doc in chunks\n",
    "                    if any(keyword in doc.page_content.lower() for keyword in keywords)\n",
    "                ]\n",
    "                if not filtered_docs:\n",
    "                    return \"No relevant information found in the CTSE lecture notes.\", \"\"\n",
    "                temp_vector_store = FAISS.from_documents(filtered_docs, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "                temp_qa_chain = RetrievalQA.from_chain_type(\n",
    "                    llm=llm,\n",
    "                    chain_type=\"stuff\",\n",
    "                    retriever=temp_vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                    return_source_documents=True,\n",
    "                    chain_type_kwargs={\"prompt\": qa_chain.combine_documents_chain.llm_chain.prompt}\n",
    "                )\n",
    "                result = temp_qa_chain.invoke({\"query\": question})\n",
    "\n",
    "            answer = result[\"result\"].strip()\n",
    "            answer = clean_text(answer)  # Ensure clean and concise output\n",
    "            source = result[\"source_documents\"][0].page_content[:200] + \"...\" if result[\"source_documents\"] else \"No source available.\"\n",
    "            source = clean_text(source)\n",
    "            logging.info(f\"Question: {question}\")\n",
    "            logging.info(f\"Answer: {answer}\")\n",
    "            return answer, source\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing question: {e}\")\n",
    "            return f\"Error: Unable to process question. {e}\", \"\"\n",
    "    return \"Chatbot not initialized.\", \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf01fb8",
   "metadata": {},
   "source": [
    "Test Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac37933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTSE Lecture Notes Chatbot ✨ (Gemma:2b + LangChain)\n",
      "Type 'exit' to stop the chatbot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 20:15:05,870 - INFO - Use pytorch device_name: cpu\n",
      "2025-05-12 20:15:05,871 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-05-12 20:15:38,655 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-12 20:15:47,112 - INFO - Question: Who won the latest football match?\n",
      "2025-05-12 20:15:47,117 - INFO - Answer: The context does not provide any information about the latest football match, so i cannot answer this question from the provided context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: Who won the latest football match?\n",
      "Bot: The context does not provide any information about the latest football match, so i cannot answer this question from the provided context.\n",
      "Source: . •continuous deployment (cd) every change that passes all stages of the pipeline will be deployed into production (released to customers). this practice fully automates the whole release flow without...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 20:16:04,677 - INFO - Use pytorch device_name: cpu\n",
      "2025-05-12 20:16:04,684 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-05-12 20:16:21,972 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-12 20:16:39,854 - INFO - Question: What is zero padding in boundary handling?\n",
      "2025-05-12 20:16:39,858 - INFO - Answer: Sure, here's the answer to your question: **zero padding in boundary handling refers to the process of adding zeros to the border of an image to ensure that the filter can be applied to the entire image area.**\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: What is zero padding in boundary handling?\n",
      "Bot: Sure, here's the answer to your question: **zero padding in boundary handling refers to the process of adding zeros to the border of an image to ensure that the filter can be applied to the entire image area.**\n",
      "Source: . boundary issues: when processing pixels near the edges of an image, special handling is needed because some neighboring pixels might be outside the image boundary. mask math: the new pixel value is ...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 20:16:56,187 - INFO - Use pytorch device_name: cpu\n",
      "2025-05-12 20:16:56,191 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-05-12 20:18:28,083 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-12 20:19:04,395 - INFO - Question: What are the key principles of DevOps?\n",
      "2025-05-12 20:19:04,405 - INFO - Answer: Sure, here are the key principles of devops from the context: implement gradual changes with frequent deployments. leverage tooling and automation to reduce manual work. leverage risktaking mindset. continuously provide value to customers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: What are the key principles of DevOps?\n",
      "Bot: Sure, here are the key principles of devops from the context: implement gradual changes with frequent deployments. leverage tooling and automation to reduce manual work. leverage risktaking mindset. continuously provide value to customers.\n",
      "Source: ... implement gradual changes frequent deployments, frequent deterministic releases in small chunks which can be rolled backaccept failure as normal blameless pms/ rca. risk taking mindset. leverage t...\n",
      "--------------------------------------------------\n",
      "\n",
      "Chat History:\n",
      "You: Who won the latest football match?\n",
      "Bot: The context does not provide any information about the latest football match, so i cannot answer this question from the provided context.\n",
      "Source: . •continuous deployment (cd) every change that passes all stages of the pipeline will be deployed into production (released to customers). this practice fully automates the whole release flow without...\n",
      "--------------------------------------------------\n",
      "You: What is zero padding in boundary handling?\n",
      "Bot: Sure, here's the answer to your question: **zero padding in boundary handling refers to the process of adding zeros to the border of an image to ensure that the filter can be applied to the entire image area.**\n",
      "Source: . boundary issues: when processing pixels near the edges of an image, special handling is needed because some neighboring pixels might be outside the image boundary. mask math: the new pixel value is ...\n",
      "--------------------------------------------------\n",
      "You: What are the key principles of DevOps?\n",
      "Bot: Sure, here are the key principles of devops from the context: implement gradual changes with frequent deployments. leverage tooling and automation to reduce manual work. leverage risktaking mindset. continuously provide value to customers.\n",
      "Source: ... implement gradual changes frequent deployments, frequent deterministic releases in small chunks which can be rolled backaccept failure as normal blameless pms/ rca. risk taking mindset. leverage t...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot in Jupyter Notebook\n",
    "chat_history = []\n",
    "\n",
    "print(\"CTSE Lecture Notes Chatbot ✨ (Gemma:2b + LangChain)\")\n",
    "print(\"Type 'exit' to stop the chatbot.\")\n",
    "while True:\n",
    "    question = input(\"Ask a question about CTSE Software Engineering: \")\n",
    "    if question.lower() == \"exit\":\n",
    "        break\n",
    "    if question:\n",
    "        answer, source = ask_question(question)\n",
    "        chat_history.append({\"question\": question, \"answer\": answer, \"source\": source})\n",
    "        print(\"\\nYou:\", question)\n",
    "        print(\"Bot:\", answer)\n",
    "        print(\"Source:\", source)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Display chat history\n",
    "print(\"\\nChat History:\")\n",
    "for chat in chat_history:\n",
    "    print(\"You:\", chat[\"question\"])\n",
    "    print(\"Bot:\", chat[\"answer\"])\n",
    "    print(\"Source:\", chat[\"source\"])\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
