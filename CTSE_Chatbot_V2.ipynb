{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72401823",
   "metadata": {},
   "source": [
    "# CTSE Lecture Notes Chatbot (Enhanced)\n",
    "## SE4010 AI/ML Assignment\n",
    "This Jupyter Notebook implements an optimized Retrieval-Augmented Generation (RAG) chatbot for answering questions based on CTSE lecture notes. Enhancements include persistent vector storage, semantic chunking, advanced embeddings, error handling, and an interactive interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b7b47",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8f8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging for debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253617b",
   "metadata": {},
   "source": [
    "## 2. Load and Process Lecture Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d2dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:12:43,488 - INFO - Loading PDF files...\n",
      "2025-05-09 03:12:43,892 - WARNING - Ignoring wrong pointing object 14 0 (offset 0)\n",
      "2025-05-09 03:12:43,894 - WARNING - Ignoring wrong pointing object 20 0 (offset 0)\n",
      "2025-05-09 03:12:43,895 - WARNING - Ignoring wrong pointing object 24 0 (offset 0)\n",
      "2025-05-09 03:12:43,896 - WARNING - Ignoring wrong pointing object 26 0 (offset 0)\n",
      "2025-05-09 03:12:43,897 - WARNING - Ignoring wrong pointing object 58 0 (offset 0)\n",
      "2025-05-09 03:12:43,898 - WARNING - Ignoring wrong pointing object 60 0 (offset 0)\n",
      "2025-05-09 03:12:43,899 - WARNING - Ignoring wrong pointing object 62 0 (offset 0)\n",
      "2025-05-09 03:12:43,901 - WARNING - Ignoring wrong pointing object 64 0 (offset 0)\n",
      "2025-05-09 03:12:43,903 - WARNING - Ignoring wrong pointing object 89 0 (offset 0)\n",
      "2025-05-09 03:12:43,905 - WARNING - Ignoring wrong pointing object 121 0 (offset 0)\n",
      "2025-05-09 03:12:43,907 - WARNING - Ignoring wrong pointing object 157 0 (offset 0)\n",
      "2025-05-09 03:12:43,908 - WARNING - Ignoring wrong pointing object 159 0 (offset 0)\n",
      "2025-05-09 03:12:43,909 - WARNING - Ignoring wrong pointing object 182 0 (offset 0)\n",
      "2025-05-09 03:12:43,915 - WARNING - Ignoring wrong pointing object 300 0 (offset 0)\n",
      "2025-05-09 03:12:43,916 - WARNING - Ignoring wrong pointing object 302 0 (offset 0)\n",
      "2025-05-09 03:12:43,919 - WARNING - Ignoring wrong pointing object 351 0 (offset 0)\n",
      "2025-05-09 03:12:43,922 - WARNING - Ignoring wrong pointing object 427 0 (offset 0)\n",
      "2025-05-09 03:12:44,216 - WARNING - Ignoring wrong pointing object 14 0 (offset 0)\n",
      "2025-05-09 03:12:44,216 - WARNING - Ignoring wrong pointing object 20 0 (offset 0)\n",
      "2025-05-09 03:12:44,217 - WARNING - Ignoring wrong pointing object 22 0 (offset 0)\n",
      "2025-05-09 03:12:44,217 - WARNING - Ignoring wrong pointing object 24 0 (offset 0)\n",
      "2025-05-09 03:12:44,220 - WARNING - Ignoring wrong pointing object 54 0 (offset 0)\n",
      "2025-05-09 03:12:44,221 - WARNING - Ignoring wrong pointing object 56 0 (offset 0)\n",
      "2025-05-09 03:12:44,222 - WARNING - Ignoring wrong pointing object 58 0 (offset 0)\n",
      "2025-05-09 03:12:44,222 - WARNING - Ignoring wrong pointing object 60 0 (offset 0)\n",
      "2025-05-09 03:12:44,224 - WARNING - Ignoring wrong pointing object 84 0 (offset 0)\n",
      "2025-05-09 03:12:44,226 - WARNING - Ignoring wrong pointing object 160 0 (offset 0)\n",
      "2025-05-09 03:12:44,227 - WARNING - Ignoring wrong pointing object 162 0 (offset 0)\n",
      "2025-05-09 03:12:44,229 - WARNING - Ignoring wrong pointing object 197 0 (offset 0)\n",
      "2025-05-09 03:12:44,230 - WARNING - Ignoring wrong pointing object 199 0 (offset 0)\n",
      "2025-05-09 03:12:44,231 - WARNING - Ignoring wrong pointing object 201 0 (offset 0)\n",
      "2025-05-09 03:12:44,233 - WARNING - Ignoring wrong pointing object 261 0 (offset 0)\n",
      "2025-05-09 03:12:44,236 - WARNING - Ignoring wrong pointing object 295 0 (offset 0)\n",
      "2025-05-09 03:12:44,239 - WARNING - Ignoring wrong pointing object 394 0 (offset 0)\n",
      "2025-05-09 03:12:45,027 - INFO - Splitting documents into chunks...\n",
      "2025-05-09 03:12:45,045 - INFO - Created 124 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Check if lecture_notes folder exists\n",
    "notes_dir = './lecture_notes/'\n",
    "if not os.path.exists(notes_dir):\n",
    "    logging.error(f\"Directory {notes_dir} not found. Please create it and add PDF files.\")\n",
    "    raise FileNotFoundError(f\"Directory {notes_dir} not found.\")\n",
    "\n",
    "# Load PDFs with progress bar\n",
    "logging.info(\"Loading PDF files...\")\n",
    "loader = PyPDFDirectoryLoader(notes_dir)\n",
    "try:\n",
    "    documents = loader.load()\n",
    "    if not documents:\n",
    "        logging.error(\"No documents loaded. Ensure PDFs are text-based and not empty.\")\n",
    "        raise ValueError(\"No documents loaded.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading PDFs: {e}\")\n",
    "    raise\n",
    "\n",
    "# Semantic chunking for better context\n",
    "logging.info(\"Splitting documents into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Smaller chunks for efficiency\n",
    "    chunk_overlap=100,  # Moderate overlap for context\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]  # Semantic separators\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "logging.info(f\"Created {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128c967",
   "metadata": {},
   "source": [
    "## 3. Set Up Embeddings and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f458140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:13:07,965 - INFO - Creating new FAISS index...\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1132\\2394724196.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "2025-05-09 03:13:40,236 - INFO - Use pytorch device_name: cpu\n",
      "2025-05-09 03:13:40,237 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127ecc5746f6445184497a2bf51ad6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518162029c4146099e2a3be236109c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24e74be712c49279e356540fef2f532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e55be1778841f08a82ae3f0ae5e00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f19e6e61143463fb5bc4bccbb624366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-05-09 03:13:46,874 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7703781980a844679bb733fb56a69121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e52eefec0e41b1ba0becb5dc092a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e3ba64699a41f9acdf3b40a9b6ff14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131d9c8bff02422eb258ababe408e703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdd1ed554314d88a4348364d62416cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac79326da0954f2ea05ca3d34d85f0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:14:56,854 - INFO - Loading faiss with AVX512 support.\n",
      "2025-05-09 03:14:56,870 - INFO - Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "2025-05-09 03:14:56,871 - INFO - Loading faiss with AVX2 support.\n",
      "2025-05-09 03:14:57,321 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2025-05-09 03:14:57,345 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-05-09 03:14:57,369 - INFO - Saved FAISS index to ./faiss_index\n"
     ]
    }
   ],
   "source": [
    "# Check for existing FAISS index\n",
    "faiss_index_path = './faiss_index'\n",
    "if os.path.exists(faiss_index_path):\n",
    "    logging.info(\"Loading existing FAISS index...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    logging.info(\"Creating new FAISS index...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    vector_store.save_local(faiss_index_path)\n",
    "    logging.info(f\"Saved FAISS index to {faiss_index_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313cba8",
   "metadata": {},
   "source": [
    "## 4. Set Up Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab09797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:15:16,189 - INFO - Initializing Ollama LLM...\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama LLM (Mistral)\n",
    "logging.info(\"Initializing Ollama LLM...\")\n",
    "try:\n",
    "    llm = OllamaLLM(model=\"mistral\", temperature=0.3)  # Lower temperature for precise answers\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing Ollama: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a727267",
   "metadata": {},
   "source": [
    "## 5. Build RAG Pipeline with Custom Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfb73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:16:05,995 - INFO - Building RAG pipeline...\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Custom prompt for better answer quality\n",
    "prompt_template = \"\"\"\n",
    "You are a knowledgeable assistant for Current Trends in Software Engineering (CTSE). Answer the following question based solely on the provided lecture notes. Provide a clear, concise, and accurate response. If the information is not available, say so.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Create RAG chain\n",
    "logging.info(\"Building RAG pipeline...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),  # Retrieve top 3 chunks\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7f381",
   "metadata": {},
   "source": [
    "## 6. Interactive Chatbot Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621cebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTSE Chatbot: Ask a question about the lecture notes (type 'exit' to quit)\n",
      "Exiting chatbot.\n"
     ]
    }
   ],
   "source": [
    "# Function to ask questions\n",
    "def ask_question(question):\n",
    "    try:\n",
    "        result = qa_chain({\"query\": question})\n",
    "        answer = result[\"result\"].strip()\n",
    "        source = result[\"source_documents\"][0].page_content[:200] + \"...\"\n",
    "        logging.info(f\"Question: {question}\")\n",
    "        logging.info(f\"Answer: {answer}\")\n",
    "        return answer, source\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing question: {e}\")\n",
    "        return \"Error: Unable to process question.\", \"\"\n",
    "\n",
    "# Interactive loop (run this cell to interact)\n",
    "print(\"CTSE Chatbot: Ask a question about the lecture notes (type 'exit' to quit)\")\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question.lower() == 'exit':\n",
    "        print(\"Exiting chatbot.\")\n",
    "        break\n",
    "    answer, source = ask_question(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Source: {source}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e6ea7",
   "metadata": {},
   "source": [
    "## 7. Test with Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496a27e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing questions:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1132\\3802780587.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n",
      "2025-05-09 03:19:42,295 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-09 03:21:28,946 - INFO - Question: What is the main topic of Lecture 1?\n",
      "2025-05-09 03:21:29,026 - INFO - Answer: The main topic of Lecture 1, based on the provided lecture notes, cannot be definitively determined as the information provided does not specify the subject or course name. However, the numbers \"4 V’s\" and \"11\" or \"23\" could potentially refer to concepts within the lecture, but without further context, it is impossible to accurately interpret their meaning.\n",
      "Testing questions:  33%|███▎      | 1/3 [02:15<04:31, 135.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main topic of Lecture 1?\n",
      "Answer: The main topic of Lecture 1, based on the provided lecture notes, cannot be definitively determined as the information provided does not specify the subject or course name. However, the numbers \"4 V’s\" and \"11\" or \"23\" could potentially refer to concepts within the lecture, but without further context, it is impossible to accurately interpret their meaning.\n",
      "Source: SLIIT  -Faculty of Computing\n",
      "Subject Name\n",
      "4 V’s\n",
      "11...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:21:36,589 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-09 03:24:28,382 - INFO - Question: Explain the concept from the lecture 2 notes.\n",
      "2025-05-09 03:24:28,470 - INFO - Answer: The concept discussed in the lecture 2 notes pertains to MapReduce phases, which are fundamental steps in the MapReduce programming model used for processing large datasets in a distributed manner.\n",
      "\n",
      "The Map phase takes input data and applies a mapping function to it, producing output values in the form of <key, value> pairs. In the given example, each word from the input splits is considered as a key, and its frequency of occurrence is the corresponding value.\n",
      "\n",
      "Following the Map phase, the Shuffle phase consolidates the relevant records from the Map phase output. The same words are grouped together with their respective frequencies.\n",
      "\n",
      "Finally, the Reduce phase aggregates the output values from the Shuffle phase. This phase combines the values for each key (word in this case) and returns a single output value that represents the summary or total count of that particular word across the entire dataset. In short, the Reduce phase summarizes the complete dataset based on the grouped keys.\n",
      "Testing questions:  67%|██████▋   | 2/3 [05:15<02:41, 161.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Explain the concept from the lecture 2 notes.\n",
      "Answer: The concept discussed in the lecture 2 notes pertains to MapReduce phases, which are fundamental steps in the MapReduce programming model used for processing large datasets in a distributed manner.\n",
      "\n",
      "The Map phase takes input data and applies a mapping function to it, producing output values in the form of <key, value> pairs. In the given example, each word from the input splits is considered as a key, and its frequency of occurrence is the corresponding value.\n",
      "\n",
      "Following the Map phase, the Shuffle phase consolidates the relevant records from the Map phase output. The same words are grouped together with their respective frequencies.\n",
      "\n",
      "Finally, the Reduce phase aggregates the output values from the Shuffle phase. This phase combines the values for each key (word in this case) and returns a single output value that represents the summary or total count of that particular word across the entire dataset. In short, the Reduce phase summarizes the complete dataset based on the grouped keys.\n",
      "Source: . In this phase data in each split is passed to a mapping function to produce output values. In our example, a job of mapping phase is to count a number ofoccurrences of each word from input splits an...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 03:24:37,343 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "2025-05-09 03:31:14,573 - INFO - Question: Summarize the key points of Lecture 3.\n",
      "2025-05-09 03:31:14,712 - INFO - Answer: Lecture 3, Introduction to Big Data at SLIIT - Faculty of Computing, focuses on the Four V's of Big Data: Volume, Velocity, Variety, and Veracity.\n",
      "\n",
      "1. **Volume**: This refers to the large amount of data generated every second by various sources such as social media, sensors, and transactions. The challenge lies in storing and managing this vast amount of data efficiently.\n",
      "\n",
      "2. **Velocity**: This aspect emphasizes the speed at which new data is being produced. It can be real-time data streams or historical data that needs to be processed quickly for immediate insights or analysis.\n",
      "\n",
      "3. **Variety**: Big Data comes in various formats, including structured (e.g., databases), semi-structured (e.g., XML, JSON), and unstructured data (e.g., text, images, videos). Handling this diversity is crucial for effective data processing.\n",
      "\n",
      "4. **Veracity**: This V refers to the quality or truthfulness of the data. Big Data may contain errors, inconsistencies, or inaccuracies that can affect the insights derived from it. Ensuring the data's veracity is essential for making reliable decisions based on analysis.\n",
      "\n",
      "These Four V's help us understand the characteristics and challenges associated with Big Data, providing a foundation for further study and practical application in software engineering.\n",
      "Testing questions: 100%|██████████| 3/3 [12:01<00:00, 240.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Summarize the key points of Lecture 3.\n",
      "Answer: Lecture 3, Introduction to Big Data at SLIIT - Faculty of Computing, focuses on the Four V's of Big Data: Volume, Velocity, Variety, and Veracity.\n",
      "\n",
      "1. **Volume**: This refers to the large amount of data generated every second by various sources such as social media, sensors, and transactions. The challenge lies in storing and managing this vast amount of data efficiently.\n",
      "\n",
      "2. **Velocity**: This aspect emphasizes the speed at which new data is being produced. It can be real-time data streams or historical data that needs to be processed quickly for immediate insights or analysis.\n",
      "\n",
      "3. **Variety**: Big Data comes in various formats, including structured (e.g., databases), semi-structured (e.g., XML, JSON), and unstructured data (e.g., text, images, videos). Handling this diversity is crucial for effective data processing.\n",
      "\n",
      "4. **Veracity**: This V refers to the quality or truthfulness of the data. Big Data may contain errors, inconsistencies, or inaccuracies that can affect the insights derived from it. Ensuring the data's veracity is essential for making reliable decisions based on analysis.\n",
      "\n",
      "These Four V's help us understand the characteristics and challenges associated with Big Data, providing a foundation for further study and practical application in software engineering.\n",
      "Source: SLIIT  -Faculty of Computing\n",
      "Subject Name\n",
      "MapReduce Phases\n",
      "17...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test predefined questions\n",
    "test_questions = [\n",
    "    \"What is the main topic of Lecture 1?\",\n",
    "    \"Explain the concept from the lecture 2 notes.\",\n",
    "    \"Summarize the key points of Lecture 3.\"\n",
    "]\n",
    "\n",
    "for question in tqdm(test_questions, desc=\"Testing questions\"):\n",
    "    answer, source = ask_question(question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Source: {source}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3831d",
   "metadata": {},
   "source": [
    "#Rusith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef760e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48c5e03c58c47fd996b9d30fd557573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
